{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BSD68 dataset was adapted from K. Zhang et al (TIP, 2017) and is composed of natural\n",
    "images. The noise was artificially added, allowing for quantitative comparisons with the\n",
    "ground truth, one of the benchmark used in many denoising publications. Here, we check \n",
    "the performances of Noise2Void using the Lightning API of CAREamics.\n",
    "\n",
    "This API gives you more freedom to customize the training by using wrappers around the\n",
    "main elements of CAREamics: the datasets and the lightning module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necessary to execute the code\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from PIL import Image\n",
    "from careamics.lightning import (\n",
    "    create_predict_datamodule,\n",
    "    create_train_datamodule,\n",
    ")\n",
    "from careamics.lightning.lightning_module import VAEModule\n",
    "from careamics.config import create_hdn_configuration\n",
    "from careamics.config.support import SupportedTransform\n",
    "from careamics.prediction_utils import convert_outputs\n",
    "from careamics.utils.metrics import psnr\n",
    "from careamics_portfolio import PortfolioManager\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the dataset\n",
    "\n",
    "The dataset can be directly downloaded using the `careamics-portfolio` package, which\n",
    "uses `pooch` to download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "# instantiate data portfolio manage\n",
    "portfolio = PortfolioManager()\n",
    "\n",
    "# and download the data\n",
    "root_path = Path(\"./data\")\n",
    "files = portfolio.denoising.N2V_BSD68.download(root_path)\n",
    "\n",
    "# create paths for the data\n",
    "data_path = Path(root_path / \"denoising-N2V_BSD68.unzip/BSD68_reproducibility_data\")\n",
    "train_path = data_path / \"train\"\n",
    "val_path = data_path / \"val\"\n",
    "test_path = data_path / \"test\" / \"images\"\n",
    "gt_path = data_path / \"test\" / \"gt\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training and validation image and show them side by side\n",
    "single_train_image = tifffile.imread(next(iter(train_path.rglob(\"*.tiff\"))))[0]\n",
    "single_val_image = tifffile.imread(next(iter(val_path.rglob(\"*.tiff\"))))[0]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(single_train_image, cmap=\"gray\")\n",
    "ax[0].set_title(\"Training Image\")\n",
    "ax[1].imshow(single_val_image, cmap=\"gray\")\n",
    "ax[1].set_title(\"Validation Image\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with the CAREamics Lightning API\n",
    "\n",
    "Using the Lightning API of CAREamics, you need to instantiate the lightning module, the \n",
    "data module and the trainer yourself.\n",
    "\n",
    "### Create the Lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_config = get_loss_config(**experiment_params)\n",
    "# model_config = get_model_config(**experiment_params)\n",
    "# gaussian_lik_config, noise_model_config, nm_lik_config = get_likelihood_config(\n",
    "#     **experiment_params\n",
    "# )\n",
    "# training_config = get_training_config(**experiment_params)\n",
    "\n",
    "# # setting up learning rate scheduler and optimizer (using default parameters)\n",
    "# lr_scheduler_config = get_lr_scheduler_config(**experiment_params)\n",
    "# optimizer_config = get_optimizer_config(**experiment_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = create_hdn_configuration(\n",
    "    experiment_name=\"bsd68_hdn\",\n",
    "    data_type=\"tiff\",\n",
    "    axes=\"SYX\",\n",
    "    z_dims=[32] * 4,\n",
    "    patch_size=(128, 128),\n",
    "    batch_size=64,\n",
    "    num_epochs=5,\n",
    "    predict_logvar=\"pixelwise\",\n",
    "    train_dataloader_params={\"num_workers\": 4},\n",
    "    val_dataloader_params={\"num_workers\": 4},\n",
    "    logger=None\n",
    ")\n",
    "\n",
    "print(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAEModule(config.algorithm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_module = create_train_datamodule(\n",
    "    train_data=train_path,\n",
    "    val_data=val_path,\n",
    "    data_type=config.data_config.data_type,\n",
    "    patch_size=config.data_config.patch_size,\n",
    "    axes=config.data_config.axes,\n",
    "    batch_size=config.data_config.batch_size,\n",
    "    transforms=[],\n",
    "    train_dataloader_params=config.data_config.train_dataloader_params,\n",
    "    val_dataloader_params=config.data_config.val_dataloader_params,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the trainer\n",
    "\n",
    "Note that here we modify the prediction loop, but this will be  changed in the near\n",
    "future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "# Create Callbacks\n",
    "root = Path(\"bsd68_n2v\")\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        dirpath=root / \"checkpoints\",\n",
    "        filename=\"bsd68_lightning_api\",\n",
    "        save_last=True,\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create a Lightning Trainer\n",
    "trainer = Trainer(max_epochs=config.training_config.num_epochs, default_root_dir=root, callbacks=callbacks)\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, datamodule=train_data_module)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with CAREamics Lightning API\n",
    "\n",
    "### Define the prediction datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "means, stds = train_data_module.get_data_statistics()\n",
    "pred_data_module = create_predict_datamodule(\n",
    "    pred_data=test_path,\n",
    "    data_type=\"tiff\",\n",
    "    axes=\"YX\",\n",
    "    batch_size=1,\n",
    "    tta_transforms=False, #not implemented\n",
    "    image_means=means,\n",
    "    image_stds=stds,\n",
    "    tile_size=(128, 128),\n",
    "    tile_overlap=(32, 32),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "prediction = trainer.predict(model, datamodule=pred_data_module)\n",
    "\n",
    "# Convert the outputs to the original format, mostly useful if tiling is used\n",
    "prediction = convert_outputs(prediction, tiled=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show two images\n",
    "noises = [tifffile.imread(f) for f in sorted(test_path.glob(\"*.tiff\"))]\n",
    "gts = [tifffile.imread(f) for f in sorted(gt_path.glob(\"*.tiff\"))]\n",
    "\n",
    "# images to show\n",
    "images = np.random.choice(range(len(noises)), 3)\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, figsize=(15, 15))\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(3):\n",
    "    pred_image = prediction[images[i]].squeeze()\n",
    "    psnr_noisy = psnr(gts[images[i]], noises[images[i]], data_range=noises[images[i]].max())\n",
    "    psnr_result = psnr(gts[images[i]], pred_image, pred_image.max())\n",
    "\n",
    "    ax[i, 0].imshow(noises[images[i]], cmap=\"gray\")\n",
    "    ax[i, 0].title.set_text(f\"Noisy\\nPSNR: {psnr_noisy:.2f}\")\n",
    "\n",
    "    ax[i, 1].imshow(pred_image, cmap=\"gray\")\n",
    "    ax[i, 1].title.set_text(f\"Prediction\\nPSNR: {psnr_result:.2f}\")\n",
    "\n",
    "    ax[i, 2].imshow(gts[images[i]], cmap=\"gray\")\n",
    "    ax[i, 2].title.set_text(\"Ground-truth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psnrs = np.zeros((len(prediction), 1))\n",
    "\n",
    "for i, (pred, gt) in enumerate(zip(prediction, gts)):\n",
    "    psnrs[i] = psnr(gt, pred.squeeze(), pred.max())\n",
    "\n",
    "print(f\"PSNR: {psnrs.mean():.2f} +/- {psnrs.std():.2f}\")\n",
    "print(\"Reported PSNR: 27.71\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a cover image\n",
    "im_idx = 3\n",
    "cv_image_noisy = noises[im_idx]\n",
    "cv_image_pred = prediction[im_idx].squeeze()\n",
    "\n",
    "# create image\n",
    "cover = np.zeros((256, 256))   \n",
    "(height, width) = cv_image_noisy.shape\n",
    "assert height > 256\n",
    "assert width > 256\n",
    "\n",
    "# normalize train and prediction\n",
    "norm_noise = (cv_image_noisy - cv_image_noisy.min()) / (cv_image_noisy.max() - cv_image_noisy.min())\n",
    "norm_pred = (cv_image_pred - cv_image_pred.min()) / (cv_image_pred.max() - cv_image_pred.min())\n",
    "\n",
    "# fill in halves\n",
    "cover[:, :256 // 2] = norm_noise[height // 2 - 256 // 2:height // 2 + 256 // 2, width // 2 - 256 // 2:width // 2]\n",
    "cover[:, 256 // 2:] = norm_pred[height // 2 - 256 // 2:height // 2 + 256 // 2, width // 2:width // 2 + 256 // 2]\n",
    "\n",
    "# plot the single image\n",
    "plt.imshow(cover, cmap=\"gray\")\n",
    "\n",
    "# save the image\n",
    "im = Image.fromarray(cover * 255)\n",
    "im = im.convert('L')\n",
    "im.save(\"BSD68_Noise2Void_lightning_api.jpeg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "0d2a5a3ab9ff26e8b66efec3883fa5121030bb852a7a4271db665831444e4e91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
